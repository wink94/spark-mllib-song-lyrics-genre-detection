lyrics.model.directory.path=model
lyrics.training.set.directory.path=model
lyrics.data.path=tcc_ceds_music.csv
lyrics.merged.path=Merged_dataset.csv
lyrics.pipeline=LogisticRegressionPipeline
server.port=8090

spark.master=local[1]

# Spark application name.
spark.application-name=Machine Learning with Apache Spark

# Path to distributed library that should be loaded into each worker of a Spark cluster.
spark.distributed-libraries=<spark distributed libraries path should be correct path used on different environments>

# Amount of memory to use for the driver process.
spark.driver.memory=2g

# The maximum amount of CPU cores to request for the application from across the cluster (not from each machine).
spark.cores.max=4

# Amount of memory to assign to each executor process
spark.executor.memory=4g

# The largest number of partitions in a parent RDD during distributed shuffle operations.
# For local mode should be equal to number of cores on the local machine.
spark.default.parallelism=4

# Serializer: org.apache.spark.serializer.JavaSerializer (default) or org.apache.spark.serializer.KryoSerializer
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.kryo.registrationRequired=false
spark.kryoserializer.buffer.max=128m

# The number of partitions to use when shuffling data for joins or aggregations.
spark.sql.shuffle.partitions=5
spark.driver.allowMultipleContexts = true
